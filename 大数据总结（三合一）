
12.11小结
四大方向：平台、离线、实时（11.10已梳理）、检索
组件关系的梳理：HDFS、Yarn、ZK、HBase、Hive、Loader
依赖关系：HBase依赖zk和HDFS，Hive依赖HDFS
1、平台 HDFS（存）、Yarn（算）、Zookeeper（协调）、LADP和kerbors（安全）
①HDFS   集群主要有两类问题：
                 主节点NameNode（存储元数据）   从节点DataNode（存数据）
水平瓶颈                联邦                    无限扩展
单点故障                主备                    默认3副本机制

主备：由zookeeper完成主备的切换和监控，主节点上会启动ZKFC的进程去和zk汇报心跳，主节点的元数据是存储在内存fsimage，editlog，基于JN的进程实现主备节点之间编辑日志的同步，fsimage元数据保存在内存中是瞬时状态，需要持久化的过程，持久化的动作由备NameNode实现

联邦：多个主节点之间是共用从节点的，每个从节点会把自己对应的数据汇报到相应的主节点上

HDFS适用场景：适合：大文件存储、不修改的数据、流式读取
                不适合：小文件存储、频繁修改、流数据的读写

HDFS的读写流程：客户端读写操作都是先找NameNode，NN会通知客户端所找数据的位置，读写要判断是否有权限，对应目录和文件是否存在，读写数据的顺序，先本机，再同机架，再不同机架

副本的顺序：本机，不同机架最近，同机架最远，副本以块block为单位，128M的大小

MapReduce和Yarn（2.0后才出现）
MR的适合场景
MR流程：Map分，Reduce合，洗牌（map的输出到reduce的输入）
Map：分片（默认分片的大小等于HDFS分块大小）→分区（分区的个数就是Reduce的个数）→排序合并→combiner（局部合并的操作，可以大大减少输出文件的数量和大小，默认不开启，可能会影响业务逻辑）
shuffer：把m的输出拷贝到r的输入中
Reduce阶段：不是所有的MR流程都需要Reduce，比如年龄加一

Yarn：主从结构，主节点RM，从节点NM，主节点负责所有任务的统筹，具体某一个任务的统筹ApplicationMaster（启动在NM），APPMaster会先主节点去申请资源，申请了以后通知其他的NM启动container（一般封装了CPU和内存）

容错性：就是任务的失败重试，包括M任务和R任务也一样

调度：默认任务的优先级FIFO，一般来说资源释放的任务优先级最高，还可以设置对应的最低容量保障

广义的hadoop指的是hadoop整个生态圈，狭义的hadoop就是hadoop组件，hadoop组件里就是HDFS+Yarn

Zookeeper：分布式协调，所有组件的主从都依赖于ZK实现，消息具有原子性的特点
主从的选举：zk的容错性，主节点需要半数以上的票才能当选，所以一般部署奇数台，比如30个节点的容灾能力是14和29个节点的容灾能力是一致的
组件的主备机制是由zk的几个特性来实现：①分布式锁②监听监控③临时带序号节点的特点

zk的数据类型有四中：是否带序号+临时/永久，临时节点的特点就是一旦创建该节点的服务器和zk断开连接，那么该数据消失


安全组件（待讲解梳理）

2、离线 Hive（数仓分析）、Loader（ETL数据接入）
①Loader是ETL的工具，ETL就是抽取加载转换的缩写，所谓的ETL就是把传统的数据库、传统的文件系统这些数据导入到大数据的存储介质之中，以及大数据存储介质中分析后的结构倒回到原始的传统数据库当中，Loader是华为封装了开源的sqoop，etl工具非常多，都是用图形化界面通过点击的形式完成对应的迁移，第一步配置连接，第二部配置转换的过程，转换的数据来源，转换的数据目的地，转换的中间数据逻辑

②Hive   Hive的核心就是通过HQL去完成数据的分析操作，底层就是用的MR引擎
        元数据+数据，元数据保存在关系型数据库当中，一般放在mysql，真正的数据存储在HDFS之上
        Hive的核心驱动器Driver（编译、优化、执行）
        Hive的表结构里，有托管表（内部表）、分区分桶表

内部表和外部表最大的区别：删除数据的时候，内部表全删，外部表只删除元数据，一般来说我们都创建的内部表，当多个人使用一个非常大的数据集的时候，我们建议用外部表

分区    目录    一般字段原先不存在      分区下还可以有分区和分桶        提升where查询的效率
分桶    文件    字段必须存在    分桶下不可以再有分桶和分区      提升join关联分析的效率，分桶操作底层是转换成了MR任务去执行

Hive的数据导入过程：导入的数据来源HDFS，可以是Local，导入数据不会检查数据的重复性、标准型，默认的分割符，默认行分隔符回车，默认的列分隔符\001

Hive的操作，可以用beeline链接、WebHcat等链接，操作有三种类型：DDL定义、DML管理、DQL查询

3、检索 HBase（列式数据库）
HBase就是列式数据库，列式的优点当我只需要检索一个数据的一个条目时，速度非常快
主从架构：主节点HMaster（负责表级别的内容修改），从节点HRegionServer（1个Hlog+多个Region）
表结构模型：一张表初始状态创建时只有一个Region，Region下有CF的概念，CF对应的物理结构是Store（分为内存和磁盘），数据是先写入内存Store，待内存Store数据快满时flush到磁盘中，数据是先写Hlog再写内存Store，此机制是为了保证数据的安全完整性，最小的单元就是cell，cell下还有对应的时间戳
Spilit：Region级别的分，横着切，保证数据的高效访问
Compact：同一个R，同一个CF下的Hfile过多时会合并
存储模型：K-V结构，K就是RowKey的概念，K是唯一的，而且默认按照字典序进行排序，HBase数据底层就是以HFile的格式存储在HDFS之上，支持高效的查询检索的业务
HBase寻址的过程：有两张系统表，一张叫作metaRegion，一张叫作UserRegion，metaRegion上记录了UserRegion具体在哪一个节点之上，metaRegion的地址存在zk之上，所以HBase单纯的读写是不经过HMaster的






---------------------------------------------------------------------------------
流处理

12.10流处理组件的内容总结：
实时流框架产生的原因：因为传统的批处理在时延上不具备对应实时流业务的需求，所有的实时框架都是基于内存的
最典型的实时流框架：Flume+Kafka+Spark/Flink
数据接入+消息中间件+具体的处理框架

Flume:实时的日志采集的工具，三大模块：Source+Channel+Sink，级联是常用在跨集群间数据传输
Source和Channel的对应关系：一对一或一对多
Source：常见的source类型，使用最多的是监控一个静态目录dir，avro和thirift两种方式可以作级联
Channel：三种类型；内存（快、会丢）、磁盘、JDBC
Sink：最常见的sink——hdfs用作批处理，hbase用作检索，kafka用作实时流处理
Flume驱动方式是events事件

Kafka:消息中间件产品，发布订阅模型，发布者生产者，订阅者消费者，集群是由broker组成
确定一条消息：Topic话题主题+partition+offset
kafka数据分为索引index文件和数据文件sigamafile，index索引加载进内存，采用稀疏存储的方式，sigamafile的特点是多个小文件段，方便已消费的数据及时删除
副本有主从，数据是不断在变化的，主副本负责变，从副本负责同步主副本的数据，副本最重要的特点不能在同一个节点之上
生产者和消费者对应broker的关系，生产者用push，消费者用pull
数据存储用副本来保证对应的数据丢失情况，数据传输kafka用最少一次的消费场景是最多的
消费者有CG概念：同一个CG里，针对一个topic的一个partiton，只能交由1个消费者消费

Storm   事件驱动        源码是一个小语种，所以storm开发用导入JStorm的包 时延毫秒，吞吐量低      只能做流处理
Spark   时间驱动        轻（源码scala）快（内存）灵（四个解决方案）巧（可以用yarn和hdfs）       时延亚秒，吞吐量高              Spark SQL离线批处理、实时流计算、机器学习、图计算        实时流处理最核心的概念是把流数据以微小的时间单元进行切分，用微批的思想处理流数据        Spark核心是Spark Core，最终要的是RDD，默认在内存，宽窄依赖的概念和区别，Stage的划分的依据就是宽依赖
算子类型：transformation和action，前者是懒操作，后者才会真正的执行
Flink   事件驱动        源码Scala+Java  时延毫秒，吞吐量高      离线批处理、实时流计算、机器学习、图计算        实时流处理最核心的概念把流数据当成一张无边界的表
Flink的组成：Souece+transformation+Sink
容错的思想：类比我们在衣服生产的流水线上不断插入羽毛（barries）的过程，基于barries可以进行checkpoint，后续可以用savepoint操作（①多分支②高复杂度）


实时流计算框架较经常运用窗口的概念：分割方式有时间和事件，基于窗口的类型有滑动、滚动、会话
实时流数据框架关系：
Flume→Kafka→Spark/Flink结构中
Flume对于Kafka来说是生产者的关系，Kafka对于Flume来说是Sink
Flume1→Kafka→Flume2
Flume2的Kafka Source对应的是Kafka的消费者
Flume1的Kafka Sink对应的是Kafka的生产者
Kakfa的生产者对应的是Flume的sink
Kakfa的消费者对应的是Flume的Source


----------------------------------------------------------------------------------------------------

11.29总结梳理
大数据的方向梳理：
大数据出现的背景：4V特性（数据量、数据种类、数据处理速度、价值密度低）
集群发展里，有两类比较常见的问题：水平瓶颈、单点故障

1、平台侧       HDFS解决存储、Yarn计算框架、Zookeeper分布式协调、Kerberos&LDAP负责安全
①HDFS   主从结构：
主节点NameNode（单点故障用主备机制解决，水平瓶颈用联邦机制解决）        存储元数据fsimage元数据在内存，同时磁盘也会保存一份，磁盘保存元数
据fsimage的动作由备份的NN完成
从节点DataNode（水平瓶颈是不存在的可以任意扩展，单点故障问题用3副本的机制）
存储的策略：第一个副本默认是本机，第二个副本不同机架最近的节点，第三个副本同机架最远的节点

HDFS解决存储场景最大的优势是：分块存储，默认块大小是128
HDFS适合场景：大文件的存储，流式读取场景
HDFS不适合的场景：小文件的存储、流数据的读写、实时读写、数据会不断变更修改

②MapReduce和Yarn

MapReduce：Map过程和Reduce过程，我们把Map端的输出到Reduce端的输入叫做Shuffle
Map分片默认的大小就是HDFS分块的大小，Map的输出默认不合并，如果需要合并，就要开启Combiner，开启Combiner以后输出的文件大小和文件的数目会大
大减少
Shuffle会完成排序和分区的功能，Shuffle分区个数就是Reduce的个数
Reduce全局的统计和输出结果
一个完整的MR程序，是否一定要有Reduce过程？不一定
Reduce的进度是否一定等到Map达到100%才开始进行？不一定

Yarn：主从架构，主节点ResourceManager，从节点NodeManager

一个具体任务的执行是由AppMaster来统筹，AppMaster会通知RM协调对应的container资源，C里封装的就是内存和CPU资源，AM其实也就是一个特殊的C，他
们都是启动在NodeManager的进程，单个任务的失败，比如上述的某一个map task或者reduce task 失败，并不会然整个任务失败，它有对应的重试机制，包
括appmaster也类似

Yarn的最小资源保障，比如说最小资源要10%，那这个时候执行的任务同时最多可以有10个
所有的资源请求里，资源释放的请求是最优先的

③Zookeeper
分布式的协调：协调的前提是本身组件足够可靠
ZK主要做主备之间的选举和监控，以及主从的节点通信的问题

ZK完成主备的切换：①锁   ②监听监控的机制
ZK本身是一个微型数据库，它的数据叫做节点，节点有临时或永久，带序号或不带序号的特点，临时节点的特性就是创建该节点的服务器和zk断开连接后，
该数据会自动消失

zk如何去选举自己的主节点，必须获得集群半数以上的节点的票数，涉及容灾能力
比如说集群有10个节点，成为主节点需要6票，容灾能力是4
11      6       5
9       5       4
zk的选举最初的时候是基于myid来选举的，就是每个节点有个myid的配置文件，这个配置文件需要每个节点保存的数据都是不同的，要求每个节点的id是不
同的
        1       2       3       4       5
④Kerberos&LDAP
负责安全认证的组件，要关注授权一定是按时按需，就是在一定的时间内对那些数据库那些表由那些权限（读写改删）
2、离线批处理分析       Loader+Hive数仓分析
①Loader ETL的工具，抽取、转换、加载，封装的是开源sqoop，ETL的工具非常多，都是以图形化webUI的方式去配置迁移，配置输入源，配置转换的规则，
配置输出端
②Hive   OLAP作分析的数仓工具，OLTP作事务分析（传统的关系型数据库），通过把一些列的HQL转换成了MR程序去运行，步骤是编译、优化、执行
Hive把元数据存在关系型数据库中，比如mysql，把数据存在HDFS之上
内部表  文件是在hive的管辖范围内，删表时元数据和数据都会删除
外部表  文件是在hive的管辖范围外，删表时只删元数据
分区表  对应目录，分区字段是事先不存在的，可以再有分区或分桶    提升where查询性能
分桶表  对应文件，分桶字段必须事先存在，不能再分区或分桶
        提升join关联的性能

作离线分析应该是在一天的深夜的时候运行，涉及白天或夜晚的资源调度

3、实时流处理分析       Flume实时日志采集+Kafka消息中间件+Spark/Flink实时流处理框架
①Flume  实时的日志采集工具      Source（监控一个目录）+channel（内存或磁盘或JDBC）+sink(最常见是kafka和HDFS)，基于事件驱动的

②Kafka  消息中间件产品，为了解决耦合，kafka集群每一个节点叫Broker，两个角色一个是生产者，一个是消费者，巧妙的推拉模型
kafka也有对应的副本，但是kafka的副本和hdfs不同的是它有主从副本的概念，因为kafka的副本有对应的数据变化的过程，需要由一个副本负责变化，另外
的负责同步
topic+partition+offset
最多一次、最少一次、仅有一次
同步发送和异步发送的区别，同步发送指的是数据生产一条发送一条，异步发送指的是数据生产先放入内存中的环形缓冲区，当缓冲区的文件达到一定的规
模（如90%），数据再一次性写入的过程，所以用的同步发送较多

③Spark  基于批处理的思想        时间驱动（类似电梯）    时延秒  吞吐量高
流处理的核心是把流数据用微小的时间单元进行切分，切分成微批数据作处理    可以作实时流处理、离线批处理、机器学习、图计算，Spark的源码是scal
a（运行在JVM上的一门语言）

④Flink  基于流处理的思想        事件驱动（类似扶梯）    时延毫秒        吞吐量高
流处理的核心就是把流数据当成一张无边界的表      可以作实时流处理、离线批处理、机器学习、图计算，Flink的源码是scala和java，两套API，处理流
DataStream，处理批DataSet，精准一次的场景依托于checkpoint机制，微小数据单元的插入barries，savepoint机制由人工触发（多分支、多复杂度的）

窗口函数：滚动、滑动（可能有重复，3分钟密码输错5次的场景）、会话（通过两次操作的时间间隔判断是否属于同一个会话）

4、实时检索搜索 列式数据库HBase+全文检索框架ElasticSearch
①HBase
        主从结构，主节点HMaster，从节点HRegionServer
一个HRegionServer是由一个Hlog和多个R组成的，写数据会先写HLog在写memstore
表——region，刚开始建表时默认只有一个
列族——store，memstore和storefile一个在内存一个在磁盘，数据先写入内存
最小的单元cell，最小的分布式存储的单元region
基于KV结构的存储模型，K就是RowKey，唯一、默认按照字典序进行排序，基于这个特点我可以进行二级索引的应用

Split和compaction，split是针对region说的，compaction是针对同一个R下同一个CF下的小文件

9，A，C，Y四个元素对Rowkey进行分区的时候

②ElasticSearch
倒排和正排索引的区别，主从架构，EsMaster，从节点EsNode，和solr的对比

解决海量高并发场景的框架组件 Redis内存数据库
解决高并发场景、持久化的方式RDB、AOF


